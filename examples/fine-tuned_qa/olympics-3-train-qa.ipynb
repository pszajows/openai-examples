{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange; font-weight:bold\">Note: To answer questions based on text documents, we recommend the procedure in <a href=\"https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\">Question Answering using Embeddings</a>. Some of the code below may rely on <a href=\"https://github.com/openai/openai-cookbook/tree/main/transition_guides_for_deprecated_API_endpoints\">deprecated API endpoints</a>.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train a fine-tuning model specialized for Q&A\n",
    "This notebook will utilize the dataset of context, question and answer pairs to additionally create adversarial questions and context pairs, where the question was not generated on that context. In those cases the model will be prompted to answer \"No sufficient context for answering the question\". We will also train a discriminator model, which predicts whether the question can be answered based on the context or not.\n",
    "\n",
    "We will add hard adversarial examples as well, which will be based either on semantically similar sections, or neighbouring sections, originating from the same article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "      <th>context</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Summary</td>\n",
       "      <td>The 2020 Summer Olympics, officially the Games...</td>\n",
       "      <td>621</td>\n",
       "      <td>2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...</td>\n",
       "      <td>1. When were the 2020 Summer Olympics held?\\n2...</td>\n",
       "      <td>1. The 2020 Summer Olympics were held from 23 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Host city selection</td>\n",
       "      <td>The International Olympic Committee (IOC) vote...</td>\n",
       "      <td>126</td>\n",
       "      <td>2020 Summer Olympics\\nHost city selection\\n\\nT...</td>\n",
       "      <td>1. When was the host city for the 2020 Summer ...</td>\n",
       "      <td>1. The host city for the 2020 Summer Olympics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Impact of the COVID-19 pandemic</td>\n",
       "      <td>In January 2020, concerns were raised about th...</td>\n",
       "      <td>375</td>\n",
       "      <td>2020 Summer Olympics\\nImpact of the COVID-19 p...</td>\n",
       "      <td>1. What concerns were raised about the potenti...</td>\n",
       "      <td>1. Concerns were raised about the potential im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Qualifying event cancellation and postponement</td>\n",
       "      <td>Concerns about the pandemic began to affect qu...</td>\n",
       "      <td>298</td>\n",
       "      <td>2020 Summer Olympics\\nQualifying event cancell...</td>\n",
       "      <td>1. What were some of the concerns that affecte...</td>\n",
       "      <td>1. Some of the concerns that affected qualifyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020 Summer Olympics</td>\n",
       "      <td>Effect on doping tests</td>\n",
       "      <td>Mandatory doping tests were being severely res...</td>\n",
       "      <td>163</td>\n",
       "      <td>2020 Summer Olympics\\nEffect on doping tests\\n...</td>\n",
       "      <td>1. What impact did the COVID-19 pandemic have ...</td>\n",
       "      <td>1. The COVID-19 pandemic severely restricted d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                         heading  \\\n",
       "0  2020 Summer Olympics                                         Summary   \n",
       "1  2020 Summer Olympics                             Host city selection   \n",
       "2  2020 Summer Olympics                 Impact of the COVID-19 pandemic   \n",
       "3  2020 Summer Olympics  Qualifying event cancellation and postponement   \n",
       "4  2020 Summer Olympics                          Effect on doping tests   \n",
       "\n",
       "                                             content  tokens  \\\n",
       "0  The 2020 Summer Olympics, officially the Games...     621   \n",
       "1  The International Olympic Committee (IOC) vote...     126   \n",
       "2  In January 2020, concerns were raised about th...     375   \n",
       "3  Concerns about the pandemic began to affect qu...     298   \n",
       "4  Mandatory doping tests were being severely res...     163   \n",
       "\n",
       "                                             context  \\\n",
       "0  2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...   \n",
       "1  2020 Summer Olympics\\nHost city selection\\n\\nT...   \n",
       "2  2020 Summer Olympics\\nImpact of the COVID-19 p...   \n",
       "3  2020 Summer Olympics\\nQualifying event cancell...   \n",
       "4  2020 Summer Olympics\\nEffect on doping tests\\n...   \n",
       "\n",
       "                                           questions  \\\n",
       "0  1. When were the 2020 Summer Olympics held?\\n2...   \n",
       "1  1. When was the host city for the 2020 Summer ...   \n",
       "2  1. What concerns were raised about the potenti...   \n",
       "3  1. What were some of the concerns that affecte...   \n",
       "4  1. What impact did the COVID-19 pandemic have ...   \n",
       "\n",
       "                                             answers  \n",
       "0  1. The 2020 Summer Olympics were held from 23 ...  \n",
       "1  1. The host city for the 2020 Summer Olympics ...  \n",
       "2  1. Concerns were raised about the potential im...  \n",
       "3  1. Some of the concerns that affected qualifyi...  \n",
       "4  1. The COVID-19 pandemic severely restricted d...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(\"key.yaml\") as f:\n",
    "    k = yaml.load(f, Loader=yaml.loader.SafeLoader)\n",
    "openai.api_key = k[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "df = pd.read_csv('olympics-data/olympics_qa.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The 2020 Summer Olympics were held from 23 July to 8 August 2021.\\n2. The 2020 Summer Olympics were held in Tokyo, Japan.\\n3. The 2020 Summer Olympics were postponed due to the global COVID-19 pandemic.\\n4. The 2020 Summer Olympics had a total spending of over $20 billion.\\n5. Japan has hosted the Olympic Games four times, including the 2020 Summer Olympics.\\n6. Some of the new events introduced in the 2020 Summer Olympics were 3x3 basketball, freestyle BMX, mixed gender team events, madison cycling for men and women, and new sports such as baseball and softball, karate, sport climbing, surfing, and skateboarding.\\n7. The United States topped the medal count in the 2020 Summer Olympics by both total golds (39) and total medals (113).\\n8. China finished second in the medal count in the 2020 Summer Olympics, with 38 gold medals and 89 total medals.\\n9. Host nation Japan finished third in the medal count in the 2020 Summer Olympics, setting a record for the most gold medals (27) and total medals (58) ever won by their delegation at an Olympic Games.\\n10. Bermuda, the Philippines, and Qatar won their first-ever Olympic gold medals in the 2020 Summer Olympics.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"answers\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the sections into a training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we check that the separator we intend to use isn't present within the contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.context.str.contains('->').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create the fine-tuning datasets for Q&A and discriminator models\n",
    "The fine-tuning dataset is created in the following way. For every corresponding question, answer and context pair we create:\n",
    "- Positive example: correct question, answer, context pair\n",
    "- Negative examples:\n",
    "  - random negative example, where the random context is paired with the question \n",
    "  - two hard negative examples\n",
    "    - one originating from the same wikipedia article\n",
    "    - another, which is most similar to the correct context\n",
    "\n",
    "This process is noisy, as sometimes the question might be answerable given a different context, but on average we hope this won't affect the peformance too much.\n",
    "\n",
    "We apply the same process of dataset creation for both the discriminator, and the Q&A answering model. We apply the process separately for the training and testing set, to ensure that the examples from the training set don't feature within the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts = {\"context\":[], \"question\":[], \"embedding\": []}\n",
    "for i, row in df.iterrows():\n",
    "    for q in row[\"questions\"].split(\"\\n\"):\n",
    "        try:\n",
    "            emb = get_embedding(q[2:].strip())\n",
    "        except:\n",
    "            continue\n",
    "        df_contexts[\"context\"].append(row[\"context\"])\n",
    "        df_contexts[\"question\"].append(q)\n",
    "        df_contexts[\"embedding\"].append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...</td>\n",
       "      <td>1. When were the 2020 Summer Olympics held?</td>\n",
       "      <td>[0.0020419505890458822, -0.02178940176963806, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...</td>\n",
       "      <td>2. Where were the 2020 Summer Olympics held?</td>\n",
       "      <td>[0.0045273941941559315, -0.023686664178967476,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...</td>\n",
       "      <td>3. Why were the 2020 Summer Olympics postponed?</td>\n",
       "      <td>[0.013307560235261917, -0.027771182358264923, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...</td>\n",
       "      <td>4. How much money was spent on the 2020 Summer...</td>\n",
       "      <td>[0.015362625010311604, -0.021405257284641266, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...</td>\n",
       "      <td>5. How many times has Japan hosted the Olympic...</td>\n",
       "      <td>[0.015828732401132584, -0.010652724653482437, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...   \n",
       "1  2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...   \n",
       "2  2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...   \n",
       "3  2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...   \n",
       "4  2020 Summer Olympics\\nSummary\\n\\nThe 2020 Summ...   \n",
       "\n",
       "                                            question  \\\n",
       "0        1. When were the 2020 Summer Olympics held?   \n",
       "1       2. Where were the 2020 Summer Olympics held?   \n",
       "2    3. Why were the 2020 Summer Olympics postponed?   \n",
       "3  4. How much money was spent on the 2020 Summer...   \n",
       "4  5. How many times has Japan hosted the Olympic...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0020419505890458822, -0.02178940176963806, ...  \n",
       "1  [0.0045273941941559315, -0.023686664178967476,...  \n",
       "2  [0.013307560235261917, -0.027771182358264923, ...  \n",
       "3  [0.015362625010311604, -0.021405257284641266, ...  \n",
       "4  [0.015828732401132584, -0.010652724653482437, ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts = pd.DataFrame(df_contexts)\n",
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts.to_csv('olympics-data/questions_context_and_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_random_similar_contexts(question_emb, context, max_rerank=10):\n",
    "    \"\"\"\n",
    "    Find similar contexts to the given context using the search file\n",
    "    \"\"\"\n",
    "    distances = openai.embeddings_utils.distances_from_embeddings(question_emb, np.vstack(df_contexts['embedding']), distance_metric=\"cosine\")\n",
    "    neighbours = openai.embeddings_utils.indices_of_nearest_neighbors_from_distances(distances)[:max_rerank]\n",
    "    candidates = []\n",
    "    for i in neighbours:\n",
    "        if df_contexts[\"context\"].iloc[i] == context:\n",
    "            continue\n",
    "        candidates.append(df_contexts[\"context\"].iloc[i])\n",
    "    try:\n",
    "        random_candidate = random.choice(candidates)\n",
    "        return random_candidate\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020 Summer Olympics\\nSports\\n\\nThe event program for the 2020 Summer Olympics was approved by the IOC executive board on 9 June 2017. IOC president Thomas Bach stated that their goal was to give the Games \"youthful\" and \"urban\" appeal, and to increase the number of female participants.The Games featured 339 events in 33 different sports, encompassing a total of 50 disciplines. Karate, sport climbing, surfing, and skateboarding made their Olympic debut, while baseball and softball also made a one-off return to the Summer Olympics for the first time since 2008. 15 new events within existing sports were also added, including 3×3 basketball, freestyle BMX, and the return of madison cycling, as well as 9 new mixed events in several sports (table tennis, archery, judo, shooting (3), triathlon, 4 × 400 m relay running and 4 × 100 m medley swimming).In the list below, the number of events in each discipline is noted in parentheses.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_similar_contexts(df_contexts.iloc[0,2], df_contexts.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_dataset(df, discriminator=False, n_negative=1, add_related=False):\n",
    "    \"\"\"\n",
    "    Create a dataset for fine tuning the OpenAI model; either for a discriminator model, \n",
    "    or a model specializing in Q&A, where it says if no relevant context is found.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The dataframe containing the question, answer and context pairs\n",
    "    discriminator: bool\n",
    "        Whether to create a dataset for the discriminator\n",
    "    n_negative: int\n",
    "        The number of random negative samples to add (using a random context)\n",
    "    add_related: bool\n",
    "        Whether to add the related contexts to the correct context. These are hard negative examples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The dataframe containing the prompts and completions, ready for fine-tuning\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        for q, a in zip((\"1.\" + row.questions).split('\\n'), (\"1.\" + row.answers).split('\\n')):\n",
    "            if len(q) >10 and len(a) >10:\n",
    "                if discriminator:\n",
    "                    rows.append({\"prompt\":f\"{row.context}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" yes\"})\n",
    "                else:\n",
    "                    rows.append({\"prompt\":f\"{row.context}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" {a[2:].strip()}\"})\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        for q in (\"1.\" + row.questions).split('\\n'):\n",
    "            if len(q) >10:\n",
    "                for j in range(n_negative + (2 if add_related else 0)):\n",
    "                    random_context = \"\"\n",
    "                    if j == 0 and add_related:\n",
    "                        # add the related contexts based on originating from the same wikipedia page\n",
    "                        subset = df[(df.title == row.title) & (df.context != row.context)]\n",
    "                        \n",
    "                        if len(subset) < 1:\n",
    "                            continue\n",
    "                        random_context = subset.sample(1).iloc[0].context\n",
    "                    if j == 1 and add_related:\n",
    "                        # add the related contexts based on the most similar contexts according to the search\n",
    "                        for _, qe_row in df_contexts.iterrows():\n",
    "                            if qe_row[\"question\"][2:].strip() == q[2:].strip():\n",
    "                                random_context = get_random_similar_contexts(qe_row[\"embedding\"], row.context, max_rerank=10)\n",
    "                    else:\n",
    "                        while True:\n",
    "                            # add random context, which isn't the correct context\n",
    "                            random_context = df.sample(1).iloc[0].context\n",
    "                            if random_context != row.context:\n",
    "                                break\n",
    "                    if discriminator:\n",
    "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\n Related:\", \"completion\":f\" no\"})\n",
    "                    else:\n",
    "                        rows.append({\"prompt\":f\"{random_context}\\nQuestion: {q[2:].strip()}\\nAnswer:\", \"completion\":f\" No appropriate context found to answer the question.\"})\n",
    "\n",
    "    return pd.DataFrame(rows) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the same process of dataset creation for both the discriminator, and the Q&A answering model. We apply the process separately for the training and testing set, to ensure that the examples from the training set don't feature within the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, is_disc in [('discriminator', True), ('qa', False)]:\n",
    "    for train_test, dt in [('train', train_df), ('test', test_df)]:\n",
    "        ft = create_fine_tuning_dataset(dt, discriminator=is_disc, n_negative=1, add_related=True)\n",
    "        ft.to_json(f'olympics-data/{name}_{train_test}.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: discriminator\n",
      "\n",
      " Example prompt: \n",
      "\n",
      "Boxing at the 2020 Summer Olympics – Men's lightweight\n",
      "Competition format\n",
      "\n",
      "Like all Olympic boxing events, the competition is a straight single-elimination tournament. The competition begins with a preliminary round, where the number of competitors is reduced to 16, and concludes with a final. As there are fewer than 32 boxers in the competition, a number of boxers will receive a bye through the preliminary round. Both semifinal losers are awarded bronze medals.\n",
      "Bouts consist of three three-minute rounds with a one-minute break between rounds. A boxer may win by knockout or by points. Scoring is on the \"10-point-must\" system, with 5 judges scoring each round. Judges consider \"number of blows landed on the target areas, domination of the bout, technique and tactical superiority and competitiveness.\" Each judge determines a winner for each round, who receives 10 points for the round, and assigns the round's loser a number of points between 7 and 9 based on performance. The judge's scores for each round are added to give a total score for that judge. The boxer with the higher score from a majority of the judges is the winner.\n",
      "Question: 1. What is the format of the boxing competition at the 2020 Summer Olympics for men's lightweight?\n",
      " Related:\n",
      "\n",
      " Example completion: \n",
      "\n",
      " yes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data set: qa\n",
      "\n",
      " Example prompt: \n",
      "\n",
      "Boxing at the 2020 Summer Olympics – Men's lightweight\n",
      "Competition format\n",
      "\n",
      "Like all Olympic boxing events, the competition is a straight single-elimination tournament. The competition begins with a preliminary round, where the number of competitors is reduced to 16, and concludes with a final. As there are fewer than 32 boxers in the competition, a number of boxers will receive a bye through the preliminary round. Both semifinal losers are awarded bronze medals.\n",
      "Bouts consist of three three-minute rounds with a one-minute break between rounds. A boxer may win by knockout or by points. Scoring is on the \"10-point-must\" system, with 5 judges scoring each round. Judges consider \"number of blows landed on the target areas, domination of the bout, technique and tactical superiority and competitiveness.\" Each judge determines a winner for each round, who receives 10 points for the round, and assigns the round's loser a number of points between 7 and 9 based on performance. The judge's scores for each round are added to give a total score for that judge. The boxer with the higher score from a majority of the judges is the winner.\n",
      "Question: 1. What is the format of the boxing competition at the 2020 Summer Olympics for men's lightweight?\n",
      "Answer:\n",
      "\n",
      " Example completion: \n",
      "\n",
      " 1. The format of the boxing competition at the 2020 Summer Olympics for men's lightweight is a straight single-elimination tournament.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, is_disc in [('discriminator', True), ('qa', False)]:\n",
    "    ft = pd.read_json(f'olympics-data/{name}_test.jsonl', lines=True)\n",
    "    print(f\"Data set: {name}\\n\\n Example prompt: \\n\\n{ft['prompt'].iloc[0]}\\n\\n Example completion: \\n\\n{ft['completion'].iloc[0]}\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We formatted the data according to the recommendations from the fine-tuning tool, which is available using\n",
    "> openai tools fine_tunes.prepare_data -f qa_train.jsonl\n",
    "\n",
    "We highly recommend that you use this tool, which suggests improvements in your data formatting for fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below has not been started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Submit the datasets for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t \"olympics-data/discriminator_train.jsonl\" -v \"olympics-data/discriminator_test.jsonl\" --batch_size 16  --compute_classification_metrics --classification_positive_class \" yes\" --model ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t \"olympics-data/qa_train.jsonl\" -v \"olympics-data/qa_test.jsonl\" --batch_size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Using the fine-tuned models\n",
    "\n",
    "We will now use the fine-tuned discriminator and the fine-tuned Q&A model. By requesting logprobs, we can see how certain the discriminator is in a `yes` vs `no` answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_discriminator = \"curie:ft-openai-internal-2021-08-23-23-58-57\"\n",
    "ft_qa = \"curie:ft-openai-internal-2021-08-23-17-54-10\"\n",
    "\n",
    "def apply_ft_discriminator(context, question, discriminator_model):\n",
    "    \"\"\"\n",
    "    Apply the fine tuned discriminator to a question, to assess whether it can be answered from the context.\n",
    "    \"\"\"\n",
    "    prompt = f\"{context}\\nQuestion: {question}\\n Related:\"\n",
    "    result = openai.Completion.create(model=discriminator_model, prompt=prompt, max_tokens=1, temperature=0, top_p=1, n=1, logprobs=2)\n",
    "    return result['choices'][0]['logprobs']['top_logprobs']\n",
    "\n",
    "apply_ft_discriminator('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.', \n",
    "                        'What was the first human-made object in space?', ft_discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model can generalize well to different contexts and questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ft_qa_answer(context, question, answering_model):\n",
    "    \"\"\"\n",
    "    Apply the fine tuned discriminator to a question\n",
    "    \"\"\"\n",
    "    prompt = f\"{context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    result = openai.Completion.create(model=answering_model, prompt=prompt, max_tokens=30, temperature=0, top_p=1, n=1, stop=['.','\\n'])\n",
    "    return result['choices'][0]['text']\n",
    "\n",
    "apply_ft_qa_answer('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.', \n",
    "                    'What was the first human-made object in space?', ft_qa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model can answer the question, when the context is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_ft_qa_answer('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.',\n",
    "                    'What is impressive about the Soviet Union?', ft_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_ft_qa_answer('The first human-made object in space was the Soviet Union satellite Sputnik 1 on 4 October 1957.',\n",
    "                    'How many cars were produced in the Soviet Union in 1970?', ft_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model knows when to answer the question, and when to say that insufficient context is present to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine a discriminator and a base model, or a fine-tuned Q&A model. Discriminator can essentially serve as a decision whether the question can be answered given the context or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_conditionally(answering_model, discriminator_model, context, question, discriminator_logprob_yes_modifier=0):\n",
    "    logprobs = apply_ft_discriminator(context, question, discriminator_model)\n",
    "    yes_logprob = logprobs[' yes'] if ' yes' in logprobs else -100\n",
    "    no_logprob = logprobs[' no'] if ' no' in logprobs else -100\n",
    "    if yes_logprob + discriminator_logprob_yes_modifier < no_logprob:\n",
    "        return \" No appropriate context found to answer the question based on the discriminator.\"\n",
    "    return apply_ft_qa_answer(context, question, answering_model)\n",
    "answer_question_conditionally(ft_qa, ft_discriminator, \n",
    "                                \"Crowdless games are a rare although not unheard-of occurrence in sports. \\\n",
    "                                 When they do occur, it is usually the result of events beyond the control \\\n",
    "                                 of the teams or fans, such as weather-related concerns, public health concerns, \\\n",
    "                                 or wider civil disturbances unrelated to the game. For instance, \\\n",
    "                                 the COVID-19 pandemic caused many sports leagues around the world \\\n",
    "                                 to be played behind closed doors.\",\n",
    "                                \"Could weather cause a sport event to have no crowd?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function illustrates how to potentially combine a discriminator and a fine-tuned Q&A model. This gives a more fine-grained control over how certain we want the model to be before it answers the question.\n",
    "\n",
    "We'll now take a look on how answers endpoint works - combining search to retrieve the relevant context from a knowledge base, and then using the fine-tuned Q&A model to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Answering the question based on a knowledge base\n",
    "Finally we can use a logic similar to the [/answers](https://beta.openai.com/docs/api-reference/answers) endpoint, where we first search for the relevant context, and then ask a Q&A model to answer the question given that context. If you'd like to see the implementation details, check out the [`answers_with_ft.py`](answers_with_ft.py) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from answers_with_ft import answer_question\n",
    "answer_question(olympics_search_fileid, ft_qa, \"Which country won the Women's football tournament at the 2020 Olympic games?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9817b186a29e4e9713184d901f26c1ee05ad25243d878baff7f31bb1fef480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
